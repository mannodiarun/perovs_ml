{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression Example With Boston Dataset: Standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import sklearn\n",
    "import keras\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rom __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np     \n",
    "import csv \n",
    "import copy \n",
    "import random \n",
    "#import mlpy\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt \n",
    "#from mlpy import KernelRidge                                                                                                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Read Data\n",
    "ifile  = open('Data.csv', \"rt\")\n",
    "reader = csv.reader(ifile)\n",
    "csvdata=[]\n",
    "for row in reader:\n",
    "        csvdata.append(row)   \n",
    "ifile.close()\n",
    "numrow=len(csvdata)\n",
    "numcol=len(csvdata[0]) \n",
    "csvdata = np.array(csvdata).reshape(numrow,numcol)\n",
    "Index = csvdata[:,0]\n",
    "Compounds = csvdata[:,1]\n",
    "A = csvdata[:,2]\n",
    "B = csvdata[:,3]\n",
    "C = csvdata[:,4]\n",
    "PBE_latt = csvdata[:,5]\n",
    "PBE_form = csvdata[:,6]\n",
    "HSE_latt = csvdata[:,7]\n",
    "HSE_form = csvdata[:,8]\n",
    "PBE_gap  = csvdata[:,9]\n",
    "HSE_gap  = csvdata[:,10]\n",
    "Ref_ind  = csvdata[:,11]\n",
    "FOM      = csvdata[:,12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " = csvdata[:,5:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = csvdata[:,9:13]\n",
    "X = csvdata[:,13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Read Outside Data\n",
    "ifile  = open('Outside_norm.csv', \"rt\")\n",
    "reader = csv.reader(ifile)\n",
    "csvdata=[]\n",
    "for row in reader:\n",
    "        csvdata.append(row)\n",
    "ifile.close()\n",
    "numrow=len(csvdata)\n",
    "numcol=len(csvdata[0])\n",
    "csvdata = np.array(csvdata).reshape(numrow,numcol)\n",
    "Sys_out = csvdata[:,0]\n",
    "A_out   = csvdata[:,1]\n",
    "B_out   = csvdata[:,2]\n",
    "C_out   = csvdata[:,3]\n",
    "X_out = csvdata[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out = C_out.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "YY = copy.deepcopy(Y)\n",
    "XX = copy.deepcopy(X)\n",
    "n = C.size\n",
    "m = int(X.size/n)\n",
    "m_y = int(Y.size/n)\n",
    "#m_y = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Prop_train, Prop_test, Prop_train_pbe_gap, Prop_test_pbe_gap, Prop_train_hse_gap, Prop_test_hse_gap, Prop_train_ref_ind, Prop_test_ref_ind, Prop_train_fom, Prop_test_fom  =  train_test_split(XX, YY, PBE_gap, HSE_gap, Ref_ind, FOM, test_size=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_train = copy.deepcopy(X)<br>\n",
    "_test  = copy.deepcopy(X)<br>\n",
    "rop_train = copy.deepcopy(prop)<br>\n",
    "rop_test  = copy.deepcopy(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tr = int(Prop_train.size/m_y)\n",
    "n_te = int(Prop_test.size/m_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prop_train_fl = [[0.0 for a in range(m_y)] for b in range(n_tr)]\n",
    "for i in range(0,n_tr):\n",
    "    for j in range(0,m_y):\n",
    "        Prop_train_fl[i][j] = float(Prop_train[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prop_test_fl = [[0.0 for a in range(m_y)] for b in range(n_te)]\n",
    "for i in range(0,n_te):\n",
    "    for j in range(0,m_y):\n",
    "        Prop_test_fl[i][j] = float(Prop_test[i][j])\n",
    " \n",
    "X_train_fl = [[0.0 for a in range(m)] for b in range(n_tr)]\n",
    "for i in range(0,n_tr):\n",
    "    for j in range(0,m):\n",
    "        X_train_fl[i][j] = float(X_train[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_fl = [[0.0 for a in range(m)] for b in range(n_te)]\n",
    "for i in range(0,n_te):\n",
    "    for j in range(0,m):\n",
    "        X_test_fl[i][j] = float(X_test[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbe_gap_fl = [0.0]*n\n",
    "hse_gap_fl = [0.0]*n\n",
    "ref_ind_fl = [0.0]*n\n",
    "fom_fl = [0.0]*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,n):\n",
    "    pbe_gap_fl[i] = float(PBE_gap[i])\n",
    "    hse_gap_fl[i] = float(HSE_gap[i])\n",
    "    ref_ind_fl[i] = float(Ref_ind[i])\n",
    "    fom_fl[i] = float(FOM[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_range_pbe_gap = float ( np.max(pbe_gap_fl[:]) )\n",
    "min_range_pbe_gap = float ( np.min(pbe_gap_fl[:]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_range_hse_gap = float ( np.max(hse_gap_fl[:]) )\n",
    "min_range_hse_gap = float ( np.min(hse_gap_fl[:]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_range_ref_ind = float ( np.max(ref_ind_fl[:]) )\n",
    "min_range_ref_ind = float ( np.min(ref_ind_fl[:]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_range_fom = float ( np.max(fom_fl[:]) )\n",
    "min_range_fom = float ( np.min(fom_fl[:]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " NN Optimizers and Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [[0.0 for a in range(6)] for b in range(729)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = [0.00, 0.10, 0.20]\n",
    "n1 = [50, 75, 100]\n",
    "n2 = [50, 75, 100]\n",
    "lr = [0.001, 0.01, 0.1]\n",
    "ep = [200, 400, 600]\n",
    "bs = [50, 100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(0,3):\n",
    "    for b in range(0,3):\n",
    "        for c in range(0,3):\n",
    "            for d in range(0,3):\n",
    "                for e in range(0,3):\n",
    "                    for f in range(0,3):\n",
    "                        parameters[count][0] = lr[a]\n",
    "                        parameters[count][1] = n1[b]\n",
    "                        parameters[count][2] = dp[c]\n",
    "                        parameters[count][3] = n2[d]\n",
    "                        parameters[count][4] = ep[e]\n",
    "                        parameters[count][5] = bs[f]\n",
    "                        count = count+1\n",
    "                        \n",
    "                        keras.optimizers.Adam(learning_rate=lr[a], beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "                        # define base model\n",
    "                        def baseline_model():\n",
    "                            model = Sequential()\n",
    "                            model.add(Dense(m, input_dim=m, kernel_initializer='normal', activation='relu'))\n",
    "                            model.add(Dense(n1[b], kernel_initializer='normal', activation='relu'))\n",
    "                            model.add(Dropout(dp[c], input_shape=(m,)))\n",
    "                            model.add(Dense(n2[d], kernel_initializer='normal', activation='relu'))\n",
    "                            model.add(Dense(1, kernel_initializer='normal'))\n",
    "                            model.compile(loss='mean_squared_error', optimizer='Adam')\n",
    "                            return model\n",
    "                        # evaluate model with standardized dataset\n",
    "                        estimators = []\n",
    "                        estimators.append(('standardize', StandardScaler()))\n",
    "                        estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=ep[e], batch_size=bs[f], verbose=0)))\n",
    "                        pipelines.append ( Pipeline(estimators) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Train Model For PBE Band Gap ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imes = 25<br>\n",
    "imes = len(pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors = [0.0]*times\n",
    "test_errors = [0.0]*times\n",
    "nn_errors = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "Prop_train = copy.deepcopy(Prop_train_pbe_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnimplementedError",
     "evalue": " Cast string to float is not supported\n\t [[node mean_squared_error/Cast (defined at /Users/amannodi/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py:335) ]] [Op:__inference_train_function_1415]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-7002b9561f84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mX_train_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProp_train_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProp_test_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProp_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProp_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mProp_train_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mProp_pred_train_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mProp_pred_test_cv\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node mean_squared_error/Cast (defined at /Users/amannodi/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py:335) ]] [Op:__inference_train_function_1415]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,times):\n",
    "    pipeline = pipelines[np.random.randint(0,729)]\n",
    "#    pipeline = pipelines[i]\n",
    "    kf = KFold(n_splits = n_fold)\n",
    "    mse_test_cv = 0.00\n",
    "    mse_train_cv = 0.00\n",
    "    for train, test in kf.split(X_train):\n",
    "        X_train_cv, X_test_cv, Prop_train_cv, Prop_test_cv = X_train[train], X_train[test], Prop_train[train], Prop_train[test]\n",
    "        pipeline.fit(X_train_cv,Prop_train_cv)\n",
    "        Prop_pred_train_cv = pipeline.predict(X_train_cv)\n",
    "        Prop_pred_test_cv  = pipeline.predict(X_test_cv)\n",
    "        n_te_cv = Prop_test_cv.size\n",
    "        n_tr_cv = Prop_train_cv.size\n",
    "        Prop_test_cv_fl = [0.0]*n_te_cv\n",
    "        Prop_pred_test_cv_fl = [0.0]*n_te_cv\n",
    "        for aa in range(0,n_te_cv):\n",
    "            Prop_test_cv_fl[aa] = np.float(Prop_test_cv[aa])\n",
    "            Prop_pred_test_cv_fl[aa] = np.float(Prop_pred_test_cv[aa])\n",
    "        Prop_train_cv_fl = [0.0]*n_tr_cv\n",
    "        Prop_pred_train_cv_fl = [0.0]*n_tr_cv\n",
    "        for aa in range(0,n_tr_cv):\n",
    "            Prop_train_cv_fl[aa] = np.float(Prop_train_cv[aa])\n",
    "            Prop_pred_train_cv_fl[aa] = np.float(Prop_pred_train_cv[aa])\n",
    "        mse_test_cv = mse_test_cv  + sklearn.metrics.mean_squared_error(Prop_test_cv_fl, Prop_pred_test_cv_fl)\n",
    "        mse_train_cv = mse_train_cv + sklearn.metrics.mean_squared_error(Prop_train_cv_fl, Prop_pred_train_cv_fl)\n",
    "    mse_test = mse_test_cv / n_fold\n",
    "    mse_train = mse_train_cv / n_fold\n",
    "    train_errors[i] = mse_train\n",
    "    test_errors[i] = mse_test\n",
    "    nn_errors.append(pipeline)\n",
    "i_opt = np.argmin(test_errors)\n",
    "pipeline_opt = nn_errors[i_opt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors_pbe_gap = copy.deepcopy(train_errors)\n",
    "test_errors_pbe_gap  = copy.deepcopy(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_opt.fit(X_train, Prop_train)\n",
    "Pred_train = pipeline_opt.predict(X_train)\n",
    "Pred_test  = pipeline_opt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_train_pbe_gap_fl = [0.0]*n_tr\n",
    "Pred_test_pbe_gap_fl  = [0.0]*n_te\n",
    "Prop_train_pbe_gap_fl = [0.0]*n_tr\n",
    "Prop_test_pbe_gap_fl  = [0.0]*n_te\n",
    "for i in range(0,n_tr):\n",
    "    Pred_train_pbe_gap_fl[i] = np.float(Pred_train[i])\n",
    "    Prop_train_pbe_gap_fl[i] = np.float(Prop_train_pbe_gap[i])\n",
    "for i in range(0,n_te):\n",
    "    Pred_test_pbe_gap_fl[i] = np.float(Pred_test[i])\n",
    "    Prop_test_pbe_gap_fl[i] = np.float(Prop_test_pbe_gap[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Outside Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_out = pipeline_opt.predict(X_out)\n",
    "Pred_out_pbe_gap = [0.0]*n_out\n",
    "for i in range(0,n_out):\n",
    "    Pred_out_pbe_gap[i] = np.float(Pred_out[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Train Model For HSE Band Gap ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imes = 25<br>\n",
    "imes = len(pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors = [0.0]*times\n",
    "test_errors = [0.0]*times\n",
    "nn_errors = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "Prop_train = copy.deepcopy(Prop_train_hse_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,times):\n",
    "    pipeline = pipelines[np.random.randint(0,729)]\n",
    "#    pipeline = pipelines[i]\n",
    "    kf = KFold(n_splits = n_fold)\n",
    "    mse_test_cv = 0.00\n",
    "    mse_train_cv = 0.00\n",
    "    for train, test in kf.split(X_train):\n",
    "        X_train_cv, X_test_cv, Prop_train_cv, Prop_test_cv = X_train[train], X_train[test], Prop_train[train], Prop_train[test]\n",
    "        pipeline.fit(X_train_cv,Prop_train_cv)\n",
    "        Prop_pred_train_cv = pipeline.predict(X_train_cv)\n",
    "        Prop_pred_test_cv  = pipeline.predict(X_test_cv)\n",
    "        n_te_cv = Prop_test_cv.size\n",
    "        n_tr_cv = Prop_train_cv.size\n",
    "        Prop_test_cv_fl = [0.0]*n_te_cv\n",
    "        Prop_pred_test_cv_fl = [0.0]*n_te_cv\n",
    "        for aa in range(0,n_te_cv):\n",
    "            Prop_test_cv_fl[aa] = np.float(Prop_test_cv[aa])\n",
    "            Prop_pred_test_cv_fl[aa] = np.float(Prop_pred_test_cv[aa])\n",
    "        Prop_train_cv_fl = [0.0]*n_tr_cv\n",
    "        Prop_pred_train_cv_fl = [0.0]*n_tr_cv\n",
    "        for aa in range(0,n_tr_cv):\n",
    "            Prop_train_cv_fl[aa] = np.float(Prop_train_cv[aa])\n",
    "            Prop_pred_train_cv_fl[aa] = np.float(Prop_pred_train_cv[aa])\n",
    "        mse_test_cv = mse_test_cv  + sklearn.metrics.mean_squared_error(Prop_test_cv_fl, Prop_pred_test_cv_fl)\n",
    "        mse_train_cv = mse_train_cv + sklearn.metrics.mean_squared_error(Prop_train_cv_fl, Prop_pred_train_cv_fl)\n",
    "    mse_test = mse_test_cv / n_fold\n",
    "    mse_train = mse_train_cv / n_fold\n",
    "    train_errors[i] = mse_train\n",
    "    test_errors[i] = mse_test\n",
    "    nn_errors.append(pipeline)\n",
    "i_opt = np.argmin(test_errors)\n",
    "pipeline_opt = nn_errors[i_opt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors_hse_gap = copy.deepcopy(train_errors)\n",
    "test_errors_hse_gap  = copy.deepcopy(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_opt.fit(X_train,Prop_train)\n",
    "Pred_train = pipeline_opt.predict(X_train)\n",
    "Pred_test  = pipeline_opt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_train_hse_gap_fl = [0.0]*n_tr\n",
    "Pred_test_hse_gap_fl  = [0.0]*n_te\n",
    "Prop_train_hse_gap_fl = [0.0]*n_tr\n",
    "Prop_test_hse_gap_fl  = [0.0]*n_te\n",
    "for i in range(0,n_tr):\n",
    "    Pred_train_hse_gap_fl[i] = np.float(Pred_train[i])\n",
    "    Prop_train_hse_gap_fl[i] = np.float(Prop_train_hse_gap[i])\n",
    "for i in range(0,n_te):\n",
    "    Pred_test_hse_gap_fl[i] = np.float(Pred_test[i])\n",
    "    Prop_test_hse_gap_fl[i] = np.float(Prop_test_hse_gap[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Outside Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_out = pipeline_opt.predict(X_out)\n",
    "Pred_out_hse_gap = [0.0]*n_out\n",
    "for i in range(0,n_out):\n",
    "    Pred_out_hse_gap[i] = np.float(Pred_out[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Train Model For Refractive Index ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imes = 25<br>\n",
    "imes = len(pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors = [0.0]*times\n",
    "test_errors = [0.0]*times\n",
    "nn_errors = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "Prop_train = copy.deepcopy(Prop_train_ref_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,times):\n",
    "    pipeline = pipelines[np.random.randint(0,729)]\n",
    "#    pipeline = pipelines[i]\n",
    "    kf = KFold(n_splits = n_fold)\n",
    "    mse_test_cv = 0.00\n",
    "    mse_train_cv = 0.00\n",
    "    for train, test in kf.split(X_train):\n",
    "        X_train_cv, X_test_cv, Prop_train_cv, Prop_test_cv = X_train[train], X_train[test], Prop_train[train], Prop_train[test]\n",
    "        pipeline.fit(X_train_cv,Prop_train_cv)\n",
    "        Prop_pred_train_cv = pipeline.predict(X_train_cv)\n",
    "        Prop_pred_test_cv  = pipeline.predict(X_test_cv)\n",
    "        n_te_cv = Prop_test_cv.size\n",
    "        n_tr_cv = Prop_train_cv.size\n",
    "        Prop_test_cv_fl = [0.0]*n_te_cv\n",
    "        Prop_pred_test_cv_fl = [0.0]*n_te_cv\n",
    "        for aa in range(0,n_te_cv):\n",
    "            Prop_test_cv_fl[aa] = np.float(Prop_test_cv[aa])\n",
    "            Prop_pred_test_cv_fl[aa] = np.float(Prop_pred_test_cv[aa])\n",
    "        Prop_train_cv_fl = [0.0]*n_tr_cv\n",
    "        Prop_pred_train_cv_fl = [0.0]*n_tr_cv\n",
    "        for aa in range(0,n_tr_cv):\n",
    "            Prop_train_cv_fl[aa] = np.float(Prop_train_cv[aa])\n",
    "            Prop_pred_train_cv_fl[aa] = np.float(Prop_pred_train_cv[aa])\n",
    "        mse_test_cv = mse_test_cv  + sklearn.metrics.mean_squared_error(Prop_test_cv_fl, Prop_pred_test_cv_fl)\n",
    "        mse_train_cv = mse_train_cv + sklearn.metrics.mean_squared_error(Prop_train_cv_fl, Prop_pred_train_cv_fl)\n",
    "    mse_test = mse_test_cv / n_fold\n",
    "    mse_train = mse_train_cv / n_fold\n",
    "    train_errors[i] = mse_train\n",
    "    test_errors[i] = mse_test\n",
    "    nn_errors.append(pipeline)\n",
    "i_opt = np.argmin(test_errors)\n",
    "pipeline_opt = nn_errors[i_opt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors_ref_ind = copy.deepcopy(train_errors)\n",
    "test_errors_ref_ind  = copy.deepcopy(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_opt.fit(X_train, Prop_train)\n",
    "Pred_train = pipeline_opt.predict(X_train)\n",
    "Pred_test  = pipeline_opt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_train_ref_ind_fl = [0.0]*n_tr\n",
    "Pred_test_ref_ind_fl  = [0.0]*n_te\n",
    "Prop_train_ref_ind_fl = [0.0]*n_tr\n",
    "Prop_test_ref_ind_fl  = [0.0]*n_te\n",
    "for i in range(0,n_tr):\n",
    "    Pred_train_ref_ind_fl[i] = np.float(Pred_train[i])\n",
    "    Prop_train_ref_ind_fl[i] = np.float(Prop_train_ref_ind[i])\n",
    "for i in range(0,n_te):\n",
    "    Pred_test_ref_ind_fl[i] = np.float(Pred_test[i])\n",
    "    Prop_test_ref_ind_fl[i] = np.float(Prop_test_ref_ind[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Outside Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_out = pipeline_opt.predict(X_out)\n",
    "Pred_out_ref_ind = [0.0]*n_out\n",
    "for i in range(0,n_out):\n",
    "    Pred_out_ref_ind[i] = np.float(Pred_out[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Train Model For Figure of Merit ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imes = 25<br>\n",
    "imes = len(pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors = [0.0]*times\n",
    "test_errors = [0.0]*times\n",
    "nn_errors = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "Prop_train = copy.deepcopy(Prop_train_fom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,times):\n",
    "    pipeline = pipelines[np.random.randint(0,729)]\n",
    "#    pipeline = pipelines[i]\n",
    "    kf = KFold(n_splits = n_fold)\n",
    "    mse_test_cv = 0.00\n",
    "    mse_train_cv = 0.00\n",
    "    for train, test in kf.split(X_train):\n",
    "        X_train_cv, X_test_cv, Prop_train_cv, Prop_test_cv = X_train[train], X_train[test], Prop_train[train], Prop_train[test]\n",
    "        pipeline.fit(X_train_cv,Prop_train_cv)\n",
    "        Prop_pred_train_cv = pipeline.predict(X_train_cv)\n",
    "        Prop_pred_test_cv  = pipeline.predict(X_test_cv)\n",
    "        n_te_cv = Prop_test_cv.size\n",
    "        n_tr_cv = Prop_train_cv.size\n",
    "        Prop_test_cv_fl = [0.0]*n_te_cv\n",
    "        Prop_pred_test_cv_fl = [0.0]*n_te_cv\n",
    "        for aa in range(0,n_te_cv):\n",
    "            Prop_test_cv_fl[aa] = np.float(Prop_test_cv[aa])\n",
    "            Prop_pred_test_cv_fl[aa] = np.float(Prop_pred_test_cv[aa])\n",
    "        Prop_train_cv_fl = [0.0]*n_tr_cv\n",
    "        Prop_pred_train_cv_fl = [0.0]*n_tr_cv\n",
    "        for aa in range(0,n_tr_cv):\n",
    "            Prop_train_cv_fl[aa] = np.float(Prop_train_cv[aa])\n",
    "            Prop_pred_train_cv_fl[aa] = np.float(Prop_pred_train_cv[aa])\n",
    "        mse_test_cv = mse_test_cv  + sklearn.metrics.mean_squared_error(Prop_test_cv_fl, Prop_pred_test_cv_fl)\n",
    "        mse_train_cv = mse_train_cv + sklearn.metrics.mean_squared_error(Prop_train_cv_fl, Prop_pred_train_cv_fl)\n",
    "    mse_test = mse_test_cv / n_fold\n",
    "    mse_train = mse_train_cv / n_fold\n",
    "    train_errors[i] = mse_train\n",
    "    test_errors[i] = mse_test\n",
    "    nn_errors.append(pipeline)\n",
    "i_opt = np.argmin(test_errors)\n",
    "pipeline_opt = nn_errors[i_opt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors_fom = copy.deepcopy(train_errors)\n",
    "test_errors_fom  = copy.deepcopy(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_opt.fit(X_train,Prop_train)\n",
    "Pred_train = pipeline_opt.predict(X_train)\n",
    "Pred_test  = pipeline_opt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_train_fom_fl = [0.0]*n_tr\n",
    "Pred_test_fom_fl  = [0.0]*n_te\n",
    "Prop_train_fom_fl = [0.0]*n_tr\n",
    "Prop_test_fom_fl  = [0.0]*n_te\n",
    "for i in range(0,n_tr):\n",
    "    Pred_train_fom_fl[i] = np.float(Pred_train[i])\n",
    "    Prop_train_fom_fl[i] = np.float(Prop_train_fom[i])\n",
    "for i in range(0,n_te):\n",
    "    Pred_test_fom_fl[i] = np.float(Pred_test[i])\n",
    "    Prop_test_fom_fl[i] = np.float(Prop_test_fom[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Outside Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_out = pipeline_opt.predict(X_out)\n",
    "Pred_out_fom = [0.0]*n_out\n",
    "for i in range(0,n_out):\n",
    "    Pred_out_fom[i] = np.float(Pred_out[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [[0.0 for a in range(8)] for b in range(times)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,times):\n",
    "    errors[i][0] = train_errors_pbe_gap[i]\n",
    "    errors[i][1] = test_errors_pbe_gap[i]\n",
    "    errors[i][2] = train_errors_hse_gap[i]\n",
    "    errors[i][3] = test_errors_hse_gap[i]\n",
    "    errors[i][4] = train_errors_ref_ind[i]\n",
    "    errors[i][5] = test_errors_ref_ind[i]\n",
    "    errors[i][6] = train_errors_fom[i]\n",
    "    errors[i][7] = test_errors_fom[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('errors.txt', errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_out = [[0.0 for a in range(4)] for b in range(n_out)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,n_out):\n",
    "    Pred_out[i][0] = Pred_out_pbe_gap[i]\n",
    "    Pred_out[i][1] = Pred_out_hse_gap[i]\n",
    "    Pred_out[i][2] = Pred_out_ref_ind[i]\n",
    "    Pred_out[i][3] = Pred_out_fom[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Pred_out.txt', Pred_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test_prop  = sklearn.metrics.mean_squared_error(Prop_test_pbe_gap_fl, Pred_test_pbe_gap_fl)\n",
    "mse_train_prop = sklearn.metrics.mean_squared_error(Prop_train_pbe_gap_fl, Pred_train_pbe_gap_fl)\n",
    "rmse_test_pbe_gap  = np.sqrt(mse_test_prop)\n",
    "rmse_train_pbe_gap = np.sqrt(mse_train_prop)\n",
    "print('rmse_test_pbe_gap = ', np.sqrt(mse_test_prop))\n",
    "print('rmse_train_pbe_gap = ', np.sqrt(mse_train_prop))\n",
    "print('      ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test_prop  = sklearn.metrics.mean_squared_error(Prop_test_hse_gap_fl, Pred_test_hse_gap_fl)\n",
    "mse_train_prop = sklearn.metrics.mean_squared_error(Prop_train_hse_gap_fl, Pred_train_hse_gap_fl)\n",
    "rmse_test_hse_gap  = np.sqrt(mse_test_prop)\n",
    "rmse_train_hse_gap = np.sqrt(mse_train_prop)\n",
    "print('rmse_test_hse_gap = ', np.sqrt(mse_test_prop))\n",
    "print('rmse_train_hse_gap = ', np.sqrt(mse_train_prop))\n",
    "print('      ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test_prop  = sklearn.metrics.mean_squared_error(Prop_test_ref_ind_fl, Pred_test_ref_ind_fl)\n",
    "mse_train_prop = sklearn.metrics.mean_squared_error(Prop_train_ref_ind_fl, Pred_train_ref_ind_fl)\n",
    "rmse_test_ref_ind  = np.sqrt(mse_test_prop)\n",
    "rmse_train_ref_ind = np.sqrt(mse_train_prop)\n",
    "print('rmse_test_ref_ind = ', np.sqrt(mse_test_prop))\n",
    "print('rmse_train_ref_ind = ', np.sqrt(mse_train_prop))\n",
    "print('      ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test_prop  = sklearn.metrics.mean_squared_error(Prop_test_fom_fl, Pred_test_fom_fl)\n",
    "mse_train_prop = sklearn.metrics.mean_squared_error(Prop_train_fom_fl, Pred_train_fom_fl)\n",
    "rmse_test_fom  = np.sqrt(mse_test_prop)\n",
    "rmse_train_fom = np.sqrt(mse_train_prop)\n",
    "print('rmse_test_fom = ', np.sqrt(mse_test_prop))\n",
    "print('rmse_train_fom = ', np.sqrt(mse_train_prop))\n",
    "print('      ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ML Parity Plots ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ig, ( [ax1, ax2], [ax3, ax4], [ax5, ax6] ) = plt.subplots( nrows=3, ncols=2, figsize=(6,6) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ig, ( [ax1, ax2], [ax3, ax4] ) = plt.subplots( nrows=2, ncols=2, sharex=True, sharey=True, figsize=(8,8) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ( [ax1, ax2], [ax3, ax4] ) = plt.subplots( nrows=2, ncols=2, figsize=(8,8) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ig, ( [ax1, ax2, ax3] ) = plt.subplots( nrows=1, ncols=3, figsize=(12,4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.text(0.5, 0.02, 'DFT Calculation', ha='center', fontsize=32)\n",
    "fig.text(0.01, 0.5, 'ML Prediction', va='center', rotation='vertical', fontsize=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ig, axes2d = plt.subplots(nrows=3, ncols=3, sharex=True, sharey=True, figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots_adjust(left=0.12, bottom=0.12, right=0.97, top=0.94, wspace=0.3, hspace=0.35)\n",
    "plt.rc('font', family='Arial narrow')\n",
    "#plt.tight_layout()\n",
    "#plt.tight_layout(pad=0.6, w_pad=0.5, h_pad=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lt.ylabel('ML Prediction', fontname='Arial Narrow', size=32)<br>\n",
    "lt.xlabel('DFT Calculation', fontname='Arial Narrow', size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prop_train_temp = copy.deepcopy(Prop_train_pbe_gap_fl)\n",
    "Pred_train_temp = copy.deepcopy(Pred_train_pbe_gap_fl)\n",
    "Prop_test_temp  = copy.deepcopy(Prop_test_pbe_gap_fl)\n",
    "Pred_test_temp  = copy.deepcopy(Pred_test_pbe_gap_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [-175,0,125]\n",
    "b = [-175,0,125]\n",
    "ax1.plot(b, a, c='k', ls='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1.xaxis.set_tick_params(labelsize=20)\n",
    "ax1.yaxis.set_tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1.scatter(Prop_train_temp[:], Pred_train_temp[:], c='blue', marker='s', s=60, edgecolors='dimgrey', alpha=1.0, label='Training')\n",
    "ax1.scatter(Prop_test_temp[:], Pred_test_temp[:], c='orange', marker='s', s=60, edgecolors='dimgrey', alpha=0.2, label='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = '%.2f' % rmse_test_pbe_gap\n",
    "tr = '%.2f' % rmse_train_pbe_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1.text(2.95, 0.8, 'Test_rmse = ', c='r', fontsize=12)\n",
    "ax1.text(4.61, 0.8, te, c='r', fontsize=12)\n",
    "ax1.text(5.22, 0.8, 'eV', c='r', fontsize=12)\n",
    "ax1.text(2.84, 0.32, 'Train_rmse = ', c='r', fontsize=12)\n",
    "ax1.text(4.60, 0.32, tr, c='r', fontsize=12)\n",
    "ax1.text(5.22, 0.32, 'eV', c='r', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1.set_ylim([-0.2, 5.8])\n",
    "ax1.set_xlim([-0.2, 5.8])\n",
    "ax1.set_xticks([1, 2, 3, 4, 5])\n",
    "ax1.set_yticks([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1.set_title('PBE Band Gap (eV)', c='k', fontsize=20, pad=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1.legend(loc='upper left',ncol=1, frameon=True, prop={'family':'Arial narrow','size':12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prop_train_temp = copy.deepcopy(Prop_train_hse_gap_fl)\n",
    "Pred_train_temp = copy.deepcopy(Pred_train_hse_gap_fl)\n",
    "Prop_test_temp  = copy.deepcopy(Prop_test_hse_gap_fl)\n",
    "Pred_test_temp  = copy.deepcopy(Pred_test_hse_gap_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [-175,0,125]\n",
    "b = [-175,0,125]\n",
    "ax2.plot(b, a, c='k', ls='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2.xaxis.set_tick_params(labelsize=20)\n",
    "ax2.yaxis.set_tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2.scatter(Prop_train_temp[:], Pred_train_temp[:], c='blue', marker='s', s=60, edgecolors='dimgrey', alpha=1.0, label='Training')\n",
    "ax2.scatter(Prop_test_temp[:], Pred_test_temp[:], c='orange', marker='s', s=60, edgecolors='dimgrey', alpha=0.2, label='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = '%.2f' % rmse_test_hse_gap\n",
    "tr = '%.2f' % rmse_train_hse_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2.text(4.03, 1.65, 'Test_rmse = ', c='r', fontsize=12)\n",
    "ax2.text(5.95, 1.65, te, c='r', fontsize=12)\n",
    "ax2.text(6.67, 1.65, 'eV', c='r', fontsize=12)\n",
    "ax2.text(3.94, 1.10, 'Train_rmse = ', c='r', fontsize=12)\n",
    "ax2.text(5.95, 1.10, tr, c='r', fontsize=12)\n",
    "ax2.text(6.67, 1.10, 'eV', c='r', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2.set_ylim([0.5, 7.3])\n",
    "ax2.set_xlim([0.5, 7.3])\n",
    "ax2.set_xticks([1, 3, 5, 7])\n",
    "ax2.set_yticks([1, 3, 5, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2.set_title('HSE Band Gap (eV)', c='k', fontsize=20, pad=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prop_train_temp = copy.deepcopy(Prop_train_ref_ind_fl)\n",
    "Pred_train_temp = copy.deepcopy(Pred_train_ref_ind_fl)\n",
    "Prop_test_temp  = copy.deepcopy(Prop_test_ref_ind_fl)\n",
    "Pred_test_temp  = copy.deepcopy(Pred_test_ref_ind_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [-175,0,125]\n",
    "b = [-175,0,125]\n",
    "ax3.plot(b, a, c='k', ls='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax3.xaxis.set_tick_params(labelsize=20)\n",
    "ax3.yaxis.set_tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax3.scatter(Prop_train_temp[:], Pred_train_temp[:], c='blue', marker='s', s=60, edgecolors='dimgrey', alpha=1.0, label='Training')\n",
    "ax3.scatter(Prop_test_temp[:], Pred_test_temp[:], c='orange', marker='s', s=60, edgecolors='dimgrey', alpha=0.2, label='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = '%.2f' % rmse_test_ref_ind\n",
    "tr = '%.2f' % rmse_train_ref_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax3.text(2.30, 1.6, 'Test_rmse = ', c='r', fontsize=12)\n",
    "ax3.text(2.85, 1.6, te, c='r', fontsize=12)\n",
    "ax3.text(3.05, 1.6, 'eV', c='r', fontsize=12)\n",
    "ax3.text(2.28, 1.43, 'Train_rmse = ', c='r', fontsize=12)\n",
    "ax3.text(2.85, 1.43, tr, c='r', fontsize=12)\n",
    "ax3.text(3.05, 1.43, 'eV', c='r', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax3.set_ylim([1.25, 3.25])\n",
    "ax3.set_xlim([1.25, 3.25])\n",
    "ax3.set_xticks([1.5, 2.0, 2.5, 3.0])\n",
    "ax3.set_yticks([1.5, 2.0, 2.5, 3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax3.set_title('Refractive Index', c='k', fontsize=20, pad=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prop_train_temp = copy.deepcopy(Prop_train_fom_fl)\n",
    "Pred_train_temp = copy.deepcopy(Pred_train_fom_fl)\n",
    "Prop_test_temp  = copy.deepcopy(Prop_test_fom_fl)\n",
    "Pred_test_temp  = copy.deepcopy(Pred_test_fom_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [-175,0,125]\n",
    "b = [-175,0,125]\n",
    "ax4.plot(b, a, c='k', ls='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax4.xaxis.set_tick_params(labelsize=20)\n",
    "ax4.yaxis.set_tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax4.scatter(Prop_train_temp[:], Pred_train_temp[:], c='blue', marker='s', s=60, edgecolors='dimgrey', alpha=1.0, label='Training')\n",
    "ax4.scatter(Prop_test_temp[:], Pred_test_temp[:], c='orange', marker='s', s=60, edgecolors='dimgrey', alpha=0.2, label='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = '%.2f' % rmse_test_fom\n",
    "tr = '%.2f' % rmse_train_fom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax4.text(3.61, 2.2, 'Test_rmse = ', c='r', fontsize=12)\n",
    "ax4.text(4.7, 2.2, te, c='r', fontsize=12)\n",
    "ax4.text(5.1, 2.2, 'eV', c='r', fontsize=12)\n",
    "ax4.text(3.55, 1.85, 'Train_rmse = ', c='r', fontsize=12)\n",
    "ax4.text(4.7, 1.85, tr, c='r', fontsize=12)\n",
    "ax4.text(5.1, 1.85, 'eV', c='r', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax4.set_ylim([1.5, 5.5])\n",
    "ax4.set_xlim([1.5, 5.5])\n",
    "ax4.set_xticks([2.0, 3.0, 4.0, 5.0])\n",
    "ax4.set_yticks([2.0, 3.0, 4.0, 5.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax4.set_title('Figure of Merit (log$_{10}$)', c='k', fontsize=20, pad=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lt.tick_params(axis='y', which='both', labelleft=True, labelright=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lt.ylabel('ML Prediction', fontname='Arial Narrow', size=32)<br>\n",
    "lt.xlabel('DFT Calculation', fontname='Arial Narrow', size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lt.rc('xtick', c='k', labelsize=16)<br>\n",
    "lt.rc('ytick', c='k', labelsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('plot.eps', dpi=450)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
